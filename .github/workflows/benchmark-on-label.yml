name: On-demand Benchmark

on:
  pull_request_target:
    types: [labeled]

concurrency:
  group: valkey-pr-benchmark
  cancel-in-progress: false

defaults:
  run:
    shell: "bash -Eeuo pipefail -x {0}"

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  benchmark:
    runs-on: ${{ github.repository == 'valkey-io/valkey' && fromJSON('["self-hosted","ec2-ubuntu-24.04-benchmarking"]') || 'ubuntu-latest' }}
    if: |
      github.event.action == 'labeled' && github.event.label.name == 'run-benchmark'
    steps:
      - name: Checkout valkey
        uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1
        with:
          path: valkey
          fetch-depth: 0
          ref: ${{ github.event.pull_request.merge_commit_sha }}
          persist-credentials: false

      - name: Checkout valkey-perf-benchmark
        uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1
        with:
          repository: ${{ github.repository_owner }}/valkey-perf-benchmark
          path: valkey-perf-benchmark
          fetch-depth: 1
          persist-credentials: false

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        working-directory: valkey-perf-benchmark
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential
          pip install -r requirements.txt

      - name: Run benchmarks
        timeout-minutes: 60
        working-directory: valkey-perf-benchmark
        run: |
          CONFIG_FILE="../valkey/.github/benchmark_configs/pr_benchmark.json"

          # Base benchmark arguments
          BENCHMARK_ARGS=(
            --commits "${{ github.event.pull_request.merge_commit_sha }}"
            --baseline "${{ github.event.pull_request.base.ref }}"
            --results-dir "results"
            --valkey-path "../valkey"
            --config "$CONFIG_FILE"
          )

          # Add server and client CPU ranges for official repository as we are running on a metal instance
          if [[ "${{ github.repository }}" == "valkey-io/valkey" ]]; then
            BENCHMARK_ARGS+=(--server-cpu-range 92-93)
            BENCHMARK_ARGS+=(--client-cpu-range 94-95)
          fi

          # Run benchmark
          python ./benchmark.py "${BENCHMARK_ARGS[@]}"

      - name: Compare results
        working-directory: valkey-perf-benchmark
        run: |
          python ./utils/compare_benchmark_results.py \
            ./results/${{ github.event.pull_request.base.ref }}/metrics.json \
            ./results/${{ github.event.pull_request.merge_commit_sha }}/metrics.json \
            ../comparison.md

      - name: Upload artifacts
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b # v4.5.0
        with:
          name: benchmark-results
          path: |
            ./valkey-perf-benchmark/results/${{ github.event.pull_request.merge_commit_sha }}/metrics.json
            ./valkey-perf-benchmark/results/${{ github.event.pull_request.base.ref }}/metrics.json
            comparison.md

      - name: Comment PR with results
        uses: actions/github-script@5c56fde4671bc2d3592fb0f2c5b5bab9ddae03b1 # v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const body = fs.readFileSync('comparison.md', 'utf8');
            const {owner, repo} = context.repo;
            const sha = '${{ github.event.pull_request.head.sha }}';
            const short = sha.slice(0,7);
            const link = `[\`${short}\`](https://github.com/${owner}/${repo}/commit/${sha})`
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner,
              repo,
              body: `**Benchmark ran on this commit:** ${link}\n\n${body}`
            });

      - name: Remove ${{ github.event.label.name }} label
        if: always() && github.event.label.name == 'run-benchmark'
        uses: actions/github-script@5c56fde4671bc2d3592fb0f2c5b5bab9ddae03b1 # v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            await github.rest.issues.removeLabel({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: '${{ github.event.label.name }}'
            }).catch(err => console.log('label not present', err.message));
